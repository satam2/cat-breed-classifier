{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "267ae6e2",
            "metadata": {},
            "source": [
                "# CNN Model & Training\n",
                "**Author:** Sandy Tam\n",
                "<br>\n",
                "\n",
                "**Dataset:** Kaggle - Cat Breeds Dataset\n",
                "\n",
                "This notebook documents the definition and training of my CNN model.  "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feffe586",
            "metadata": {},
            "source": [
                "#### Import libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6dbfd44c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision import datasets, transforms\n",
                "\n",
                "# -------- UNCOMMENT IF USING GPU MEMORY --------\n",
                "# import.cuda.amp import autocast, GradScaler\n",
                "# torch.cuda.empty_cache()\n",
                "# gc.collect()\n",
                "\n",
                "# torch.backends.cudnn.benchmark = True\n",
                "\n",
                "if torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "elif torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "print(\"Using device:\", device)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "76095b4e",
            "metadata": {},
            "source": [
                "#### Implement checkpoint system"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "524a72b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_checkpoint(model, optimizer, scheduler, epoch, history, kernel_size, \n",
                "                   checkpoint_dir='checkpoints', is_best=False):\n",
                "    \"\"\"Save training checkpoint.\"\"\"\n",
                "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
                "    torch.cuda.empty_cache()\n",
                "    \n",
                "    checkpoint = {\n",
                "        'epoch': epoch,\n",
                "        'model_state_dict': model.state_dict(),\n",
                "        'optimizer_state_dict': optimizer.state_dict(),\n",
                "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
                "        'history': history,\n",
                "        'kernel_size': kernel_size,\n",
                "        'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
                "        'gpu_memory_peak': torch.cuda.max_memory_allocated(0) / 1e9\n",
                "    }\n",
                "    \n",
                "    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_k{kernel_size}_epoch{epoch}.pt')\n",
                "    torch.save(checkpoint, checkpoint_path)\n",
                "    print(f\"Saved: {checkpoint_path}\")\n",
                "    \n",
                "    if is_best:\n",
                "        best_path = os.path.join(checkpoint_dir, f'best_model_k{kernel_size}.pt')\n",
                "        torch.save(checkpoint, best_path)\n",
                "        print(f\"Best model saved!\")\n",
                "    \n",
                "    latest_path = os.path.join(checkpoint_dir, f'latest_k{kernel_size}.pt')\n",
                "    torch.save(checkpoint, latest_path)\n",
                "    \n",
                "    return checkpoint_path\n",
                "\n",
                "\n",
                "def load_checkpoint(checkpoint_path, model, optimizer=None, scheduler=None, device='cuda'):\n",
                "    \"\"\"Load checkpoint and resume training.\"\"\"\n",
                "    if not os.path.exists(checkpoint_path):\n",
                "        return 0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "    \n",
                "    print(f\"\\nLoading checkpoint: {checkpoint_path}\")\n",
                "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
                "    \n",
                "    model.load_state_dict(checkpoint['model_state_dict'])\n",
                "    if optimizer:\n",
                "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
                "    if scheduler and checkpoint.get('scheduler_state_dict'):\n",
                "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
                "    \n",
                "    start_epoch = checkpoint['epoch'] + 1\n",
                "    history = checkpoint['history']\n",
                "    \n",
                "    print(f\"Resuming from epoch {start_epoch}\")\n",
                "    if history['val_acc']:\n",
                "        print(f\"  Best val acc so far: {max(history['val_acc']):.2f}%\\n\")\n",
                "    \n",
                "    return start_epoch, history\n",
                "\n",
                "\n",
                "def find_latest_checkpoint(kernel_size, checkpoint_dir='checkpoints'):\n",
                "    \"\"\"Find the most recent checkpoint.\"\"\"\n",
                "    latest_path = os.path.join(checkpoint_dir, f'latest_k{kernel_size}.pt')\n",
                "    return latest_path if os.path.exists(latest_path) else None\n",
                "\n",
                "\n",
                "def list_checkpoints(checkpoint_dir='checkpoints'):\n",
                "    \"\"\"List all checkpoints.\"\"\"\n",
                "    if not os.path.exists(checkpoint_dir):\n",
                "        print(\"No checkpoints found\")\n",
                "        return\n",
                "    \n",
                "    checkpoints = sorted([f for f in os.listdir(checkpoint_dir) if f.endswith('.pt')])\n",
                "    if not checkpoints:\n",
                "        print(\"No checkpoints found\")\n",
                "        return\n",
                "    \n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"Available Checkpoints ({len(checkpoints)} files)\")\n",
                "    print(f\"{'='*70}\")\n",
                "    \n",
                "    for cp in checkpoints:\n",
                "        cp_path = os.path.join(checkpoint_dir, cp)\n",
                "        try:\n",
                "            checkpoint = torch.load(cp_path, map_location='cpu')\n",
                "            best_val = max(checkpoint['history']['val_acc']) if checkpoint['history']['val_acc'] else 0\n",
                "            print(f\"{cp}: Epoch {checkpoint['epoch']} | Val Acc {best_val:.2f}%\")\n",
                "        except:\n",
                "            print(f\"{cp} (unable to load)\")\n",
                "    print(f\"{'='*70}\\n\")\n",
                "\n",
                "\n",
                "print(\"Checkpoint system loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75123a81",
            "metadata": {},
            "source": [
                "#### Define CNN class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b944c764",
            "metadata": {},
            "outputs": [],
            "source": [
                "class CatBreedCNN(nn.Module):\n",
                "    def __init__(self, num_classes=66, kernel_size=3):\n",
                "        super(CatBreedCNN, self).__init__()\n",
                "        \n",
                "        padding = kernel_size // 2\n",
                "        \n",
                "        # Block 1\n",
                "        self.conv1 = nn.Conv2d(3, 64, kernel_size, padding=padding)\n",
                "        self.bn1 = nn.BatchNorm2d(64)\n",
                "        self.conv2 = nn.Conv2d(64, 64, kernel_size, padding=padding)\n",
                "        self.bn2 = nn.BatchNorm2d(64)\n",
                "        \n",
                "        # Block 2\n",
                "        self.conv3 = nn.Conv2d(64, 128, kernel_size, padding=padding)\n",
                "        self.bn3 = nn.BatchNorm2d(128)\n",
                "        self.conv4 = nn.Conv2d(128, 128, kernel_size, padding=padding)\n",
                "        self.bn4 = nn.BatchNorm2d(128)\n",
                "        \n",
                "        # Block 3\n",
                "        self.conv5 = nn.Conv2d(128, 256, kernel_size, padding=padding)\n",
                "        self.bn5 = nn.BatchNorm2d(256)\n",
                "        self.conv6 = nn.Conv2d(256, 256, kernel_size, padding=padding)\n",
                "        self.bn6 = nn.BatchNorm2d(256)\n",
                "        \n",
                "        # Block 4\n",
                "        self.conv7 = nn.Conv2d(256, 512, kernel_size, padding=padding)\n",
                "        self.bn7 = nn.BatchNorm2d(512)\n",
                "        self.conv8 = nn.Conv2d(512, 512, kernel_size, padding=padding)\n",
                "        self.bn8 = nn.BatchNorm2d(512)\n",
                "        \n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "        self.dropout = nn.Dropout(0.5)\n",
                "        self.relu = nn.ReLU()\n",
                "        \n",
                "        # Adaptive pooling to handle any input size\n",
                "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
                "        \n",
                "        # Fully connected layers\n",
                "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
                "        self.fc2 = nn.Linear(1024, 512)\n",
                "        self.fc3 = nn.Linear(512, num_classes)\n",
                "\n",
                "    def forward(self, x):\n",
                "        # Block 1\n",
                "        x = self.relu(self.bn1(self.conv1(x)))\n",
                "        x = self.relu(self.bn2(self.conv2(x)))\n",
                "        x = self.pool(x)\n",
                "        \n",
                "        # Block 2\n",
                "        x = self.relu(self.bn3(self.conv3(x)))\n",
                "        x = self.relu(self.bn4(self.conv4(x)))\n",
                "        x = self.pool(x)\n",
                "        \n",
                "        # Block 3\n",
                "        x = self.relu(self.bn5(self.conv5(x)))\n",
                "        x = self.relu(self.bn6(self.conv6(x)))\n",
                "        x = self.pool(x)\n",
                "        \n",
                "        # Block 4\n",
                "        x = self.relu(self.bn7(self.conv7(x)))\n",
                "        x = self.relu(self.bn8(self.conv8(x)))\n",
                "        x = self.pool(x)\n",
                "        \n",
                "        # Adaptive pooling\n",
                "        x = self.adaptive_pool(x)\n",
                "        \n",
                "        # Flatten\n",
                "        x = x.view(x.size(0), -1)\n",
                "        \n",
                "        # FC layers\n",
                "        x = self.dropout(x)\n",
                "        x = self.relu(self.fc1(x))\n",
                "        x = self.dropout(x)\n",
                "        x = self.relu(self.fc2(x))\n",
                "        x = self.fc3(x)\n",
                "        \n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2b771199",
            "metadata": {},
            "source": [
                "#### Data Loading and Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0e3d4381",
            "metadata": {},
            "outputs": [],
            "source": [
                "# hyperparameters\n",
                "BATCH_SIZE = 32\n",
                "LEARNING_RATE = 0.001\n",
                "NUM_EPOCHS = 250  \n",
                "KERNEL_SIZE = 5\n",
                "TARGET_SIZE = (224, 224)\n",
                "\n",
                "# data directories\n",
                "TRAIN_DIR = 'data/train'\n",
                "TEST_DIR = 'data/test'\n",
                "\n",
                "# transforms\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(256),\n",
                "    transforms.CenterCrop(224),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(\n",
                "        mean=[0.485, 0.456, 0.406],  \n",
                "        std=[0.229, 0.224, 0.225]\n",
                "    )\n",
                "])\n",
                "\n",
                "# load the datasets\n",
                "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=transform)\n",
                "test_dataset = datasets.ImageFolder(root=TEST_DIR, transform=transform)\n",
                "\n",
                "# data loaders\n",
                "train_loader = DataLoader(\n",
                "    dataset=train_dataset,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=True,\n",
                "    num_workers=2,              \n",
                "    pin_memory=True,         \n",
                "    prefetch_factor=2  \n",
                ")\n",
                "\n",
                "test_loader = DataLoader(\n",
                "    dataset=test_dataset,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    shuffle=False,\n",
                "    num_workers=2,           \n",
                "    pin_memory=True          \n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d584d527",
            "metadata": {},
            "outputs": [],
            "source": [
                "# helper training function\n",
                "def train_and_validate_with_checkpoints(model, train_loader, val_loader, criterion, \n",
                "                                        optimizer, scheduler=None, num_epochs=10, \n",
                "                                        device='cuda', kernel_size=3, \n",
                "                                        checkpoint_dir='checkpoints',\n",
                "                                        resume_from=None, use_mixed_precision=True):\n",
                "    \"\"\"Crash-resistant training with automatic checkpointing.\"\"\"\n",
                "    \n",
                "    model = model.to(device)\n",
                "    \n",
                "    # auto-resume from checkpoint\n",
                "    if resume_from is None:\n",
                "        resume_from = find_latest_checkpoint(kernel_size, checkpoint_dir)\n",
                "    \n",
                "    if resume_from:\n",
                "        # load checkpoint with map_location to ensure everything goes to correct device\n",
                "        print(f\"\\nLoading checkpoint: {resume_from}\")\n",
                "        checkpoint = torch.load(resume_from, map_location=device)\n",
                "        \n",
                "        # load model state\n",
                "        model.load_state_dict(checkpoint['model_state_dict'])\n",
                "        \n",
                "        model = model.to(device)\n",
                "        \n",
                "        # load optimizer state\n",
                "        if optimizer and 'optimizer_state_dict' in checkpoint:\n",
                "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
                "            # move optimizer states to device\n",
                "            for state in optimizer.state.values():\n",
                "                for k, v in state.items():\n",
                "                    if isinstance(v, torch.Tensor):\n",
                "                        state[k] = v.to(device)\n",
                "        \n",
                "        # load scheduler state\n",
                "        if scheduler and checkpoint.get('scheduler_state_dict'):\n",
                "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
                "        \n",
                "        start_epoch = checkpoint['epoch'] + 1\n",
                "        history = checkpoint['history']\n",
                "        best_val_acc = max(history['val_acc']) if history['val_acc'] else 0.0\n",
                "        \n",
                "        print(f\"Resuming from epoch {start_epoch}\")\n",
                "        if history['val_acc']:\n",
                "            print(f\"  Best val acc so far: {best_val_acc:.2f}%\\n\")\n",
                "    else:\n",
                "        start_epoch = 0\n",
                "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
                "        best_val_acc = 0.0\n",
                "        print(f\"Starting fresh training\")\n",
                "    \n",
                "    # ensure model is in training mode and on correct device\n",
                "    model = model.to(device)\n",
                "    \n",
                "    # initialize scaler\n",
                "    scaler = GradScaler() if use_mixed_precision else None\n",
                "    \n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(f\"Kernel {kernel_size} | Epochs {start_epoch+1}-{num_epochs} | Mixed Precision: {use_mixed_precision}\")\n",
                "    print(f\"Device: {next(model.parameters()).device}\")  # verify model device\n",
                "    print(f\"{'='*70}\\n\")\n",
                "    \n",
                "    try:\n",
                "        for epoch in range(start_epoch, num_epochs):\n",
                "            torch.cuda.empty_cache()\n",
                "            gc.collect()\n",
                "            \n",
                "            epoch_start = time.time()\n",
                "            \n",
                "            # TRAINING\n",
                "            model.train()\n",
                "            train_loss = 0.0\n",
                "            train_correct = 0\n",
                "            train_total = 0\n",
                "            \n",
                "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
                "                images = images.to(device, non_blocking=True)\n",
                "                labels = labels.to(device, non_blocking=True)\n",
                "                \n",
                "                optimizer.zero_grad(set_to_none=True)\n",
                "                \n",
                "                if use_mixed_precision:\n",
                "                    with autocast():\n",
                "                        outputs = model(images)\n",
                "                        loss = criterion(outputs, labels)\n",
                "                    scaler.scale(loss).backward()\n",
                "                    scaler.step(optimizer)\n",
                "                    scaler.update()\n",
                "                else:\n",
                "                    outputs = model(images)\n",
                "                    loss = criterion(outputs, labels)\n",
                "                    loss.backward()\n",
                "                    optimizer.step()\n",
                "                \n",
                "                train_loss += loss.item()\n",
                "                _, predicted = torch.max(outputs.data, 1)\n",
                "                train_total += labels.size(0)\n",
                "                train_correct += (predicted == labels).sum().item()\n",
                "                \n",
                "                if (batch_idx + 1) % 20 == 0:\n",
                "                    print(f\"Epoch {epoch+1} Train: [{batch_idx+1}/{len(train_loader)}]\", end='\\r')\n",
                "            \n",
                "            avg_train_loss = train_loss / len(train_loader)\n",
                "            avg_train_acc = 100 * train_correct / train_total\n",
                "            \n",
                "            torch.cuda.empty_cache()\n",
                "            \n",
                "            # VALIDATION\n",
                "            model.eval()\n",
                "            val_loss = 0.0\n",
                "            val_correct = 0\n",
                "            val_total = 0\n",
                "            \n",
                "            with torch.no_grad():\n",
                "                for images, labels in val_loader:\n",
                "                    images = images.to(device, non_blocking=True)\n",
                "                    labels = labels.to(device, non_blocking=True)\n",
                "                    \n",
                "                    if use_mixed_precision:\n",
                "                        with autocast():\n",
                "                            outputs = model(images)\n",
                "                            loss = criterion(outputs, labels)\n",
                "                    else:\n",
                "                        outputs = model(images)\n",
                "                        loss = criterion(outputs, labels)\n",
                "                    \n",
                "                    val_loss += loss.item()\n",
                "                    _, predicted = torch.max(outputs.data, 1)\n",
                "                    val_total += labels.size(0)\n",
                "                    val_correct += (predicted == labels).sum().item()\n",
                "            \n",
                "            avg_val_loss = val_loss / len(val_loader)\n",
                "            avg_val_acc = 100 * val_correct / val_total\n",
                "            \n",
                "            if scheduler:\n",
                "                scheduler.step(avg_val_acc)\n",
                "            \n",
                "            history['train_loss'].append(avg_train_loss)\n",
                "            history['train_acc'].append(avg_train_acc)\n",
                "            history['val_loss'].append(avg_val_loss)\n",
                "            history['val_acc'].append(avg_val_acc)\n",
                "            \n",
                "            is_best = avg_val_acc > best_val_acc\n",
                "            if is_best:\n",
                "                best_val_acc = avg_val_acc\n",
                "            \n",
                "            # SAVE CHECKPOINT\n",
                "            save_checkpoint(model, optimizer, scheduler, epoch, history, kernel_size, checkpoint_dir, is_best)\n",
                "            \n",
                "            epoch_time = time.time() - epoch_start\n",
                "            print(f\"\\nEpoch {epoch+1}/{num_epochs} | Time: {epoch_time/60:.1f}min\")\n",
                "            print(f\"Train: Loss={avg_train_loss:.4f} Acc={avg_train_acc:.2f}%\")\n",
                "            print(f\"Valid: Loss={avg_val_loss:.4f} Acc={avg_val_acc:.2f}%\")\n",
                "            print(f\"Best: {best_val_acc:.2f}%\\n\")\n",
                "            \n",
                "            torch.cuda.reset_peak_memory_stats()\n",
                "        \n",
                "        print(f\"\\nTraining complete! Best: {best_val_acc:.2f}%\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"\\n Error: {str(e)}\")\n",
                "        print(f\" Checkpoint saved - restart kernel and run again to resume!\")\n",
                "        raise e\n",
                "    \n",
                "    return history\n",
                "\n",
                "print(\" Training function loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3009ba2c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# list checkpoints\n",
                "list_checkpoints()\n",
                "\n",
                "# load existing\n",
                "existing = find_latest_checkpoint(kernel_size=KERNEL_SIZE)\n",
                "if existing:\n",
                "        temp_model = CatBreedCNN(kernel_size=KERNEL_SIZE)\n",
                "        start_ep, temp_hist = load_checkpoint(existing, temp_model, device=device)\n",
                "        \n",
                "        if start_ep >= NUM_EPOCHS:\n",
                "            print(f\"Already complete!\")\n",
                "            results[k] = temp_hist\n",
                "            continue\n",
                "\n",
                "# train\n",
                "model = CatBreedCNN(kernel_size=KERNEL_SIZE)\n",
                "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "# save results with checkpoints\n",
                "try:\n",
                "    history = train_and_validate_with_checkpoints(\n",
                "    model=model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=test_loader,\n",
                "    criterion=criterion,\n",
                "    optimizer=optimizer,\n",
                "    scheduler=scheduler,\n",
                "    num_epochs=NUM_EPOCHS,\n",
                "    device=device,\n",
                "    kernel_size=k,\n",
                "    use_mixed_precision=True\n",
                ")\n",
                "    results[k] = history\n",
                "\n",
                "    # cleanup\n",
                "    del model\n",
                "    torch.cuda.empty_cache()\n",
                "    gc.collect()\n",
                "            \n",
                "except Exception as e:\n",
                "    print(\"Progress saved! Restart kernel and run again.\")\n",
                "    break\n",
                "\n",
                "# summary\n",
                "if results:\n",
                "    print(f\"\\n{'='*70}\")\n",
                "    print(\"FINAL RESULTS\")\n",
                "    print(f\"{'='*70}\")\n",
                "    for k in sorted(results.keys()):\n",
                "        best = max(results[k]['val_acc']) if results[k]['val_acc'] else 0\n",
                "        print(f\"Kernel {k}: {best:.2f}%\")\n",
                "    print(f\"{'='*70}\")\n",
                "\n",
                "print(\"\\nAll epochs complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3827a269",
            "metadata": {},
            "source": [
                "#### Save the model results and training history for visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "241bfcc9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "# save model state\n",
                "torch.save(model.state_dict(), 'cat_breed_cnn_model.pth')\n",
                "\n",
                "# save history as JSON\n",
                "with open('training_history.json', 'w') as f:\n",
                "    json.dump(history, f)\n",
                "\n",
                "print(\"Model and history saved successfully.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "cs171",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
