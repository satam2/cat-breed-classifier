{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd5651b",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "**Author:** Sandy Tam\n",
    "<br>\n",
    "\n",
    "**Dataset:** Kaggle - Cat Breeds Dataset\n",
    "\n",
    "This notebook documents the full data preparation pipeline for my cat breed classification model.  \n",
    "Steps:\n",
    "\n",
    "1. Download and load the Kaggle Cat Breeds dataset.\n",
    "2. Inspect the raw directory structure and class labels.\n",
    "3. Clean the data (invalid files, empty classes, etc.).\n",
    "4. Ensure image dimension consistency.\n",
    "5. Apply data augmentation techniques to increase dataset diversity.\n",
    "6. Create the train/test splits.\n",
    "7. Save a clean, reproducible dataset layout for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18feb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce586ff7",
   "metadata": {},
   "source": [
    "## 1. Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f79130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target image size: (224, 224)\n",
      "Train/Test split: 80.0%/19.999999999999996%\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "SOURCE_DIR = \"cat-breeds\"\n",
    "OUTPUT_DIR = \"data\"\n",
    "TARGET_SIZE = (224, 224)  # Standard size for most CNN architectures\n",
    "TRAIN_SPLIT = 0.8\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'train'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR, 'test'), exist_ok=True)\n",
    "\n",
    "print(f\"Target image size: {TARGET_SIZE}\")\n",
    "print(f\"Train/Test split: {TRAIN_SPLIT*100}%/{(1-TRAIN_SPLIT)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "data_collection",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "cat-breeds not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Collect all image paths and labels\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(SOURCE_DIR):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSOURCE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m image_paths = []\n\u001b[32m      6\u001b[39m labels = []\n",
      "\u001b[31mFileNotFoundError\u001b[39m: cat-breeds not found"
     ]
    }
   ],
   "source": [
    "# Collect all image paths and labels\n",
    "if not os.path.isdir(SOURCE_DIR):\n",
    "    raise FileNotFoundError(f\"{SOURCE_DIR} not found\")\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for breed_name in os.listdir(SOURCE_DIR):\n",
    "    breed_dir = os.path.join(SOURCE_DIR, breed_name)\n",
    "    if not os.path.isdir(breed_dir):\n",
    "        continue\n",
    "    for fname in os.listdir(breed_dir):\n",
    "        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_paths.append(os.path.join(breed_dir, fname))\n",
    "            labels.append(breed_name)\n",
    "\n",
    "print(f\"Total images: {len(image_paths)}\")\n",
    "print(f\"Unique breeds: {len(set(labels))}\")\n",
    "print(f\"Example: {image_paths[0]} -> {labels[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353ba26",
   "metadata": {},
   "source": [
    "Each subfolder corresponds to a cat breed label which will be used as class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation_section",
   "metadata": {},
   "source": [
    "## 2. Data Validation and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate_images",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating images...\n",
      "Processed 1000/11284 images\n",
      "Processed 2000/11284 images\n",
      "Processed 3000/11284 images\n",
      "Processed 4000/11284 images\n",
      "Processed 5000/11284 images\n",
      "Processed 6000/11284 images\n",
      "Processed 7000/11284 images\n",
      "Processed 8000/11284 images\n",
      "Processed 9000/11284 images\n",
      "Processed 10000/11284 images\n",
      "Processed 11000/11284 images\n",
      "\n",
      "Valid images: 11284/11284\n",
      "Removed: 0 invalid images\n"
     ]
    }
   ],
   "source": [
    "def validate_image(img_path):\n",
    "    \"\"\"Check if an image can be opened and is valid.\"\"\"\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img.verify()  # Verify it's an actual image\n",
    "        # Reopen to actually load the image\n",
    "        with Image.open(img_path) as img:\n",
    "            img.load()  # Actually load image data\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid image {img_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Validate all images\n",
    "print(\"Validating images...\")\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "\n",
    "for i, (img_path, label) in enumerate(zip(image_paths, labels)):\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(image_paths)} images\")\n",
    "    if validate_image(img_path):\n",
    "        valid_images.append(img_path)\n",
    "        valid_labels.append(label)\n",
    "\n",
    "print(f\"\\nValid images: {len(valid_images)}/{len(image_paths)}\")\n",
    "print(f\"Removed: {len(image_paths) - len(valid_images)} invalid images\")\n",
    "\n",
    "image_paths = valid_images\n",
    "labels = valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "check_dimensions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing image dimensions...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnalyzing image dimensions...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m dimensions = []\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sample_size = \u001b[38;5;28mmin\u001b[39m(\u001b[32m1000\u001b[39m, \u001b[38;5;28mlen\u001b[39m(image_paths))  \u001b[38;5;66;03m# Sample to speed up analysis\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, img_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(image_paths[:sample_size]):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % \u001b[32m200\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'image_paths' is not defined"
     ]
    }
   ],
   "source": [
    "# Check current image dimensions\n",
    "print(\"\\nAnalyzing image dimensions...\")\n",
    "dimensions = []\n",
    "sample_size = min(1000, len(image_paths))  # Sample to speed up analysis\n",
    "\n",
    "for i, img_path in enumerate(image_paths[:sample_size]):\n",
    "    if (i + 1) % 200 == 0:\n",
    "        print(f\"Analyzed {i + 1}/{sample_size} images\")\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            dimensions.append(img.size)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "dimensions = np.array(dimensions)\n",
    "print(f\"\\nDimension statistics (sampled {sample_size} images):\")\n",
    "print(f\"Width  - Min: {dimensions[:, 0].min()}, Max: {dimensions[:, 0].max()}, Mean: {dimensions[:, 0].mean():.1f}\")\n",
    "print(f\"Height - Min: {dimensions[:, 1].min()}, Max: {dimensions[:, 1].max()}, Mean: {dimensions[:, 1].mean():.1f}\")\n",
    "print(f\"\\nTarget uniform size: {TARGET_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "augmentation_section",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation Pipeline\n",
    "\n",
    "We'll create augmented versions of images to increase dataset diversity. This helps prevent overfitting and improves model generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "augmentation_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAugmenter:\n",
    "    \"\"\"Handles image augmentation with various techniques.\"\"\"\n",
    "    \n",
    "    def __init__(self, target_size=(224, 224)):\n",
    "        self.target_size = target_size\n",
    "        \n",
    "    def resize_and_pad(self, img):\n",
    "        \"\"\"Resize image while maintaining aspect ratio, then pad to target size.\"\"\"\n",
    "        img = img.convert('RGB')  # Ensure RGB\n",
    "        \n",
    "        # Calculate scaling to fit within target size\n",
    "        img.thumbnail(self.target_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Create new image with padding\n",
    "        new_img = Image.new('RGB', self.target_size, (0, 0, 0))\n",
    "        paste_x = (self.target_size[0] - img.size[0]) // 2\n",
    "        paste_y = (self.target_size[1] - img.size[1]) // 2\n",
    "        new_img.paste(img, (paste_x, paste_y))\n",
    "        \n",
    "        return new_img\n",
    "    \n",
    "    def center_crop_resize(self, img):\n",
    "        \"\"\"Center crop to square and resize.\"\"\"\n",
    "        img = img.convert('RGB')\n",
    "        width, height = img.size\n",
    "        \n",
    "        # Crop to square\n",
    "        min_dim = min(width, height)\n",
    "        left = (width - min_dim) // 2\n",
    "        top = (height - min_dim) // 2\n",
    "        right = left + min_dim\n",
    "        bottom = top + min_dim\n",
    "        \n",
    "        img = img.crop((left, top, right, bottom))\n",
    "        img = img.resize(self.target_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def random_flip(self, img, p=0.5):\n",
    "        \"\"\"Randomly flip image horizontally.\"\"\"\n",
    "        if np.random.random() > p:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return img\n",
    "    \n",
    "    def random_rotation(self, img, max_angle=15):\n",
    "        \"\"\"Randomly rotate image.\"\"\"\n",
    "        angle = np.random.uniform(-max_angle, max_angle)\n",
    "        img = img.rotate(angle, resample=Image.Resampling.BILINEAR, fillcolor=(0, 0, 0))\n",
    "        return img\n",
    "    \n",
    "    def adjust_brightness(self, img, factor_range=(0.8, 1.2)):\n",
    "        \"\"\"Randomly adjust brightness.\"\"\"\n",
    "        factor = np.random.uniform(*factor_range)\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        return enhancer.enhance(factor)\n",
    "    \n",
    "    def adjust_contrast(self, img, factor_range=(0.8, 1.2)):\n",
    "        \"\"\"Randomly adjust contrast.\"\"\"\n",
    "        factor = np.random.uniform(*factor_range)\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        return enhancer.enhance(factor)\n",
    "    \n",
    "    def adjust_saturation(self, img, factor_range=(0.8, 1.2)):\n",
    "        \"\"\"Randomly adjust saturation.\"\"\"\n",
    "        factor = np.random.uniform(*factor_range)\n",
    "        enhancer = ImageEnhance.Color(img)\n",
    "        return enhancer.enhance(factor)\n",
    "    \n",
    "    def process_image(self, img_path, augment=False):\n",
    "        \"\"\"Process a single image with optional augmentation.\"\"\"\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        # Always resize to target dimensions\n",
    "        img = self.center_crop_resize(img)\n",
    "        \n",
    "        # Apply augmentations if requested\n",
    "        if augment:\n",
    "            img = self.random_flip(img)\n",
    "            img = self.random_rotation(img, max_angle=10)\n",
    "            img = self.adjust_brightness(img)\n",
    "            img = self.adjust_contrast(img)\n",
    "            img = self.adjust_saturation(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "# Initialize augmenter\n",
    "augmenter = ImageAugmenter(target_size=TARGET_SIZE)\n",
    "print(\"Image augmenter initialized\")\n",
    "print(f\"Target size: {TARGET_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_section",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_test_split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    image_paths, labels, \n",
    "    train_size=TRAIN_SPLIT, \n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=labels  # Ensure balanced split across classes\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train_paths)} images\")\n",
    "print(f\"Test set: {len(test_paths)} images\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "train_label_counts = pd.Series(train_labels).value_counts()\n",
    "print(f\"Min: {train_label_counts.min()}, Max: {train_label_counts.max()}, Mean: {train_label_counts.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processing_section",
   "metadata": {},
   "source": [
    "## 5. Process and Save Images\n",
    "\n",
    "For training data, we'll create:\n",
    "1. Original processed images (resized to consistent dimensions)\n",
    "2. Augmented versions (with transformations)\n",
    "\n",
    "For test data, we'll only resize to consistent dimensions without augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(img, output_path):\n",
    "    \"\"\"Save processed image.\"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    img.save(output_path, 'JPEG', quality=95)\n",
    "\n",
    "# Process training data with augmentation\n",
    "print(\"Processing training data...\")\n",
    "print(\"Creating original + augmented versions for each image\")\n",
    "\n",
    "for i, (img_path, label) in enumerate(zip(train_paths, train_labels)):\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(train_paths)} training images\")\n",
    "    \n",
    "    # Create breed directory\n",
    "    breed_dir = os.path.join(OUTPUT_DIR, 'train', label.lower().replace(' ', '_'))\n",
    "    os.makedirs(breed_dir, exist_ok=True)\n",
    "    \n",
    "    # Get original filename\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Save original (processed to consistent size)\n",
    "        img_original = augmenter.process_image(img_path, augment=False)\n",
    "        save_processed_image(img_original, os.path.join(breed_dir, f\"{filename}.jpg\"))\n",
    "        \n",
    "        # Save augmented version\n",
    "        img_augmented = augmenter.process_image(img_path, augment=True)\n",
    "        save_processed_image(img_augmented, os.path.join(breed_dir, f\"{filename}_aug.jpg\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTraining data processing complete! Processed {len(train_paths)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process test data (no augmentation)\n",
    "print(\"\\nProcessing test data...\")\n",
    "print(\"Creating consistent-sized images (no augmentation)\")\n",
    "\n",
    "for i, (img_path, label) in enumerate(zip(test_paths, test_labels)):\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(test_paths)} test images\")\n",
    "    \n",
    "    # Create breed directory\n",
    "    breed_dir = os.path.join(OUTPUT_DIR, 'test', label.lower().replace(' ', '_'))\n",
    "    os.makedirs(breed_dir, exist_ok=True)\n",
    "    \n",
    "    # Get original filename\n",
    "    filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    try:\n",
    "        # Save processed image (consistent size only)\n",
    "        img = augmenter.process_image(img_path, augment=False)\n",
    "        save_processed_image(img, os.path.join(breed_dir, f\"{filename}.jpg\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nTest data processing complete! Processed {len(test_paths)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_section",
   "metadata": {},
   "source": [
    "## 6. Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count processed images\n",
    "def count_images_in_dir(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        count += len([f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    return count\n",
    "\n",
    "train_count = count_images_in_dir(os.path.join(OUTPUT_DIR, 'train'))\n",
    "test_count = count_images_in_dir(os.path.join(OUTPUT_DIR, 'test'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original dataset: {len(image_paths)} images\")\n",
    "print(f\"\\nProcessed dataset:\")\n",
    "print(f\"  Training images: {train_count} (including augmented)\")\n",
    "print(f\"  Test images: {test_count}\")\n",
    "print(f\"  Total: {train_count + test_count}\")\n",
    "print(f\"\\nAugmentation factor: ~{train_count / len(train_paths):.1f}x for training data\")\n",
    "print(f\"\\nAll images standardized to: {TARGET_SIZE}\")\n",
    "print(\"\\nData saved to:\")\n",
    "print(f\"  {os.path.abspath(os.path.join(OUTPUT_DIR, 'train'))}\")\n",
    "print(f\"  {os.path.abspath(os.path.join(OUTPUT_DIR, 'test'))}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_dimensions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all images have consistent dimensions\n",
    "print(\"\\nVerifying image dimensions...\")\n",
    "sample_train_dir = os.path.join(OUTPUT_DIR, 'train')\n",
    "sample_images = []\n",
    "\n",
    "for root, dirs, files in os.walk(sample_train_dir):\n",
    "    for file in files[:10]:  # Check first 10 images\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            sample_images.append(os.path.join(root, file))\n",
    "    if len(sample_images) >= 10:\n",
    "        break\n",
    "\n",
    "all_correct = True\n",
    "for img_path in sample_images:\n",
    "    with Image.open(img_path) as img:\n",
    "        if img.size != TARGET_SIZE:\n",
    "            print(f\"WARNING: {img_path} has size {img.size}\")\n",
    "            all_correct = False\n",
    "\n",
    "if all_correct:\n",
    "    print(f\"✓ All sampled images have correct dimensions: {TARGET_SIZE}\")\n",
    "else:\n",
    "    print(\"✗ Some images have incorrect dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization_section",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_augmentations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display original vs augmented examples\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 12))\n",
    "fig.suptitle('Sample Images: Original vs Augmented', fontsize=16)\n",
    "\n",
    "sample_original_paths = train_paths[:3]\n",
    "\n",
    "for i, img_path in enumerate(sample_original_paths):\n",
    "    # Original processed\n",
    "    img_orig = augmenter.process_image(img_path, augment=False)\n",
    "    axes[i, 0].imshow(img_orig)\n",
    "    axes[i, 0].set_title('Original')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Show 3 augmented versions\n",
    "    for j in range(1, 4):\n",
    "        img_aug = augmenter.process_image(img_path, augment=True)\n",
    "        axes[i, j].imshow(img_aug)\n",
    "        axes[i, j].set_title(f'Augmented {j}')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAll processed images are {TARGET_SIZE[0]}x{TARGET_SIZE[1]} pixels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs171",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
